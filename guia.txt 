Distribuição Numérica:
Total de clientes: 10.000
Clientes sem Churn (0): 7.963 clientes (79.63%)
Clientes com Churn (1): 2.037 clientes (20.37%)
Visualização:
Gráfico de Barras (esquerda):
Mostra a contagem absoluta de clientes
Barra mais alta (≈8000) representa clientes que permaneceram
Barra mais baixa (≈2000) representa clientes que saíram
Gráfico de Pizza (direita):
Mostra a proporção relativa
Verde (79.6%): Clientes que permaneceram
Vermelho (20.4%): Clientes que saíram
Insights Importantes:
O dataset está desbalanceado (comum em problemas de churn)
Aproximadamente 1 em cada 5 clientes deixa o banco
Esta taxa de 20.37% de churn é significativa e indica uma oportunidade de melhoria
Implicações para o Modelo:
Precisaremos considerar técnicas para lidar com o desbalanceamento dos dados
Possíveis abordagens:
Oversampling da classe minoritária (SMOTE)
Undersampling da classe majoritária
Ajuste de pesos das classes
Uso de métricas apropriadas para dados desbalanceados


## 6. Conclusão da Análise Exploratória

### Insights Principais:

1. **Taxa de Churn Geral**: Aproximadamente 20.37% dos clientes saem do banco, enquanto 79.63% permanecem.

2. **Fatores Demográficos**:
   - Idade e gênero apresentam alguma influência na taxa de churn
   - Distribuições geográficas podem indicar diferentes comportamentos de churn

3. **Fatores Financeiros**:
   - Clientes com saldo zero têm taxas de churn significativamente mais altas
   - Existe uma relação entre pontuação de crédito e propensão ao churn

4. **Engajamento e Produtos**:
   - Clientes com mais produtos têm maior probabilidade de sair (especialmente com 3 ou 4 produtos)
   - Membros inativos apresentam taxas de churn significativamente mais altas
   - Curto tempo de permanência está associado a maior propensão ao churn

5. **Segmentos de Alto Risco**:
   - Clientes com 3-4 produtos e não ativos são os mais propensos a sair
   - Clientes com baixo engajamento (medido pela nossa feature engenheirada) têm maior probabilidade de churn

### Próximos Passos:

1. **Preparação de Dados**: Processamento de variáveis e feature engineering para modelagem
2. **Modelagem Preditiva**: Implementar modelos de classificação para prever o churn
3. **Interpretação do Modelo**: Identificar fatores-chave que contribuem para o churn
4. **Segmentação de Clientes**: Criar perfis de clientes para estratégias de retenção personalizadas


Abaixo a explicação das análises 

Explicação Passo a Passo das Análises de Churn de Clientes Bancários
1. Análise Estatística de Variáveis Numéricas
O que faz:
Calcula estatísticas descritivas (média, mediana, desvio padrão, mínimo, máximo e quartis) para todas as variáveis numéricas do conjunto de dados.
Fornece uma visão geral da distribuição de cada variável numérica.
Valor para o recrutador:
Demonstra habilidade em análise estatística básica
Mostra capacidade de entender as distribuições de dados financeiros
Estabelece uma base sólida para análises mais avançadas
2. Análise de Variáveis Categóricas
O que faz:
Calcula as contagens e porcentagens para cada categoria nas variáveis categóricas (país, gênero, cartão de crédito, membro ativo, churn)
Identifica a distribuição dessas variáveis e possíveis desequilíbrios
Valor para o recrutador:
Mostra capacidade de trabalhar com dados categóricos
Revela insights sobre a composição da base de clientes
Identifica possíveis vieses nos dados que poderiam afetar modelos preditivos
3. Visualização de Distribuições de Variáveis Numéricas
O que faz:
Cria histogramas com curvas de densidade para visualizar a distribuição de cada variável numérica
Identifica padrões, assimetrias e valores atípicos na distribuição
Valor para o recrutador:
Demonstra habilidades de visualização de dados
Mostra capacidade de comunicar insights visuais
Revela compreensão sobre a forma das distribuições estatísticas
4. Visualização de Variáveis Categóricas
O que faz:
Cria gráficos de barras para visualizar a frequência de cada categoria
Adiciona rótulos de porcentagem para melhor compreensão da distribuição
Valor para o recrutador:
Demonstra competência em visualizações apropriadas para dados categóricos
Mostra atenção aos detalhes com a adição de porcentagens
Facilita a compreensão da composição do conjunto de dados
5. Análise Bivariada com a Variável Alvo (Churn)
O que faz:
Relaciona cada variável preditora com a variável target (churn)
Cria visualizações específicas mostrando taxas de churn para diferentes categorias e valores
Valor para o recrutador:
Demonstra habilidade analítica para identificar fatores associados ao churn
Mostra pensamento crítico na exploração de relações causa-efeito
Revela capacidade de traduzir análises em insights de negócio
6. Relação entre Variáveis Categóricas e Churn
O que faz:
Calcula e visualiza taxas de churn para cada categoria das variáveis categóricas
Permite identificar quais categorias têm maior risco de churn
Valor para o recrutador:
Mostra habilidade em análise de segmentação de clientes
Demonstra capacidade de extrair insights acionáveis
Revela pensamento estratégico para ações de retenção de clientes
7. Relação entre Variáveis Numéricas e Churn
O que faz:
Cria boxplots para comparar a distribuição de variáveis numéricas entre clientes que saíram e permaneceram
Identifica diferenças significativas nesses grupos
Valor para o recrutador:
Demonstra capacidade de identificar diferenças estatísticas entre grupos
Mostra habilidade na identificação de variáveis preditivas
Revela compreensão de como características numéricas influenciam o comportamento do cliente
8. Visualização de Distribuições por Status de Churn
O que faz:
Usa violin plots (gráficos de violino) para visualizar a densidade e distribuição completa de variáveis numéricas por status de churn
Oferece uma visualização mais rica que boxplots, mostrando a forma das distribuições
Valor para o recrutador:
Demonstra conhecimento de visualizações avançadas
Mostra capacidade de analisar densidades e distribuições complexas
Revela compreensão profunda sobre diferenças entre grupos
9. Análise Estatística por Status de Churn
O que faz:
Calcula estatísticas descritivas separadamente para clientes que saíram e permaneceram
Permite comparação direta dos perfis estatísticos desses grupos
Valor para o recrutador:
Demonstra habilidade em análise estatística comparativa
Mostra profundidade na análise de segmentos de clientes
Fornece base quantitativa para insights de negócio
10. Testes T para Comparação de Médias
O que faz:
Realiza testes estatísticos para determinar se as diferenças nas médias entre grupos são estatisticamente significativas
Calcula p-values e estatísticas t para cada variável numérica
Valor para o recrutador:
Demonstra conhecimento de inferência estatística
Mostra rigor científico na validação de hipóteses
Revela capacidade de distinguir entre diferenças significativas e aleatórias
11. Testes Chi-Quadrado para Variáveis Categóricas
O que faz:
Realiza testes de independência chi-quadrado para determinar associações entre variáveis categóricas e churn
Identifica quais relações são estatisticamente significativas
Valor para o recrutador:
Demonstra conhecimento de testes estatísticos apropriados para dados categóricos
Mostra capacidade de quantificar a força de associações categóricas
Revela habilidade em validar estatisticamente insights qualitativos
12. Análise de Correlação Avançada
O que faz:
Calcula e visualiza a matriz de correlação entre todas as variáveis
Identifica relações lineares entre pares de variáveis
Valor para o recrutador:
Demonstra conhecimento de técnicas de análise multivariada
Mostra capacidade de identificar interdependências entre variáveis
Revela habilidade em preparar variáveis para modelagem preditiva
13. Matriz de Correlação
O que faz:
Cria um mapa de calor colorido mostrando correlações entre todas as variáveis
Facilita a identificação visual de padrões de correlação
Valor para o recrutador:
Demonstra habilidade em visualizações complexas de correlação
Mostra capacidade de resumir muita informação em uma única visualização
Revela compreensão de como múltiplas variáveis interagem
14. Correlação com Churn
O que faz:
Isola e classifica correlações específicas com a variável target (churn)
Visualiza as variáveis mais correlacionadas positiva e negativamente com churn
Valor para o recrutador:
Demonstra foco claro no problema de negócio (prever churn)
Mostra capacidade de priorização de variáveis preditivas
Revela pensamento analítico orientado a resultados
15. Segmentação de Clientes
O que faz:
Cria segmentos significativos de clientes baseados em idade, pontuação de crédito e saldo
Análise taxas de churn dentro de cada segmento
Valor para o recrutador:
Demonstra habilidade em segmentação de clientes
Mostra capacidade de criar categorias acionáveis a partir de variáveis contínuas
Revela pensamento orientado a negócios para estratégias de marketing e retenção
16. Visualização de Segmentos
O que faz:
Visualiza taxas de churn para diferentes segmentos de clientes
Identifica visualmente quais segmentos têm maior risco
Valor para o recrutador:
Demonstra capacidade de criar visualizações actionable
Mostra habilidade em comunicar insights estratégicos
Revela pensamento focado em segmentação de cliente para ações de negócio
17. Segmentação Cruzada
O que faz:
Cria heatmaps mostrando taxas de churn na interseção de duas variáveis
Identifica micro-segmentos de alto risco (combinações específicas de características)
Valor para o recrutador:
Demonstra capacidade de análise multivariada avançada
Mostra habilidade em identificar nichos específicos para ações direcionadas
Revela pensamento sofisticado sobre interações de fatores de risco
18. Feature Engineering Preliminar
O que faz:
Cria novas variáveis derivadas das existentes que podem ter maior poder preditivo
Desenvolve métricas complexas como "score de engajamento" e "proporção saldo-renda"
Valor para o recrutador:
Demonstra criatividade em engenharia de features
Mostra conhecimento em transformação e combinação de variáveis
Revela pensamento orientado a modelo para melhorar o poder preditivo
19. Análise de Novas Features
O que faz:
Avalia a correlação das novas variáveis criadas com o churn
Visualiza a distribuição dessas novas variáveis entre clientes que saíram e permaneceram
Valor para o recrutador:
Demonstra capacidade de validar a utilidade de features criadas
Mostra ciclo completo de engenharia de features: criar, testar e avaliar
Revela processo de trabalho metódico e orientado a resultados
20. Conclusão da Análise
O que faz:
Sintetiza todos os insights principais da análise
Identifica os fatores-chave associados ao churn
Recomenda próximos passos para modelagem e ações de negócios
Valor para o recrutador:
Demonstra capacidade de síntese e comunicação de resultados
Mostra habilidade em traduzir análises técnicas em insights comerciais
Revela visão do "panorama geral" além das análises individuais
Demonstra capacidade de vincular análise de dados a ações estratégicas



aseado na análise do notebook, vou fazer uma explicação detalhada de todas as métricas e resultados do modelo de churn:
Análise Exploratória dos Dados:
O dataset possui 10.000 registros com 12 variáveis
Variáveis numéricas: credit_score, age, tenure, balance, products_number, estimated_salary
Variáveis categóricas: country, gender, credit_card, active_member
Variável alvo (target): churn (0 = não cancelou, 1 = cancelou)
Distribuição do Churn:
Taxa de churn de aproximadamente 20.37% (2037 clientes)
Isso indica um desbalanceamento nas classes, onde a maioria dos clientes não cancelou
Modelos Utilizados e Métricas:
Regressão Logística:
Accuracy: 0.7025 (70.25% de acertos gerais)
Precision: 0.3792 (37.92% dos clientes previstos como churn realmente cancelaram)
Recall: 0.7248 (72.48% dos clientes que realmente cancelaram foram identificados)
F1-Score: 0.4979 (média harmônica entre precision e recall)
ROC AUC: 0.7807 (capacidade do modelo de distinguir entre as classes)
Random Forest:
Accuracy: 0.8635 (86.35% de acertos gerais)
Precision: 0.7939 (79.39% dos clientes previstos como churn realmente cancelaram)
Recall: 0.4447 (44.47% dos clientes que realmente cancelaram foram identificados)
F1-Score: 0.5701 (média harmônica entre precision e recall)
ROC AUC: 0.8520 (capacidade do modelo de distinguir entre as classes)
Interpretação das Métricas:
Accuracy (Acurácia):
Mede a proporção total de previsões corretas
Random Forest teve melhor performance com 86.35% vs 70.25% da Regressão Logística
Precision (Precisão):
Indica a proporção de previsões positivas que estavam corretas
Random Forest teve melhor precisão (79.39% vs 37.92%)
Significa que quando o modelo Random Forest prevê que um cliente vai cancelar, ele está certo em 79.39% das vezes
Recall (Sensibilidade):
Indica a proporção de casos positivos reais que foram identificados corretamente
Regressão Logística teve melhor recall (72.48% vs 44.47%)
Significa que a Regressão Logística identificou 72.48% dos clientes que realmente cancelaram
F1-Score:
Média harmônica entre precision e recall
Random Forest teve melhor F1-Score (0.5701 vs 0.4979)
Indica um melhor equilíbrio entre precision e recall
ROC AUC:
Mede a capacidade do modelo de distinguir entre as classes
Random Forest teve melhor performance (0.8520 vs 0.7807)
Valores mais próximos de 1 indicam melhor capacidade de discriminação
Validação Cruzada:
Random Forest:
Média CV Score: 0.8523 ± 0.0066
Indica consistência no desempenho do modelo
Baixa variância entre os folds (0.0066)
Regressão Logística:
Média CV Score: 0.7709 ± 0.0118
Desempenho mais baixo mas ainda consistente
Variância um pouco maior entre os folds
Conclusões:
O Random Forest foi o melhor modelo geral, com:
Maior acurácia geral (86.35%)
Melhor precisão na identificação de churn (79.39%)
Melhor capacidade de discriminação (ROC AUC = 0.8520)
A Regressão Logística teve:
Melhor recall (72.48%)
Menor precisão (37.92%)
Performance geral mais baixa mas ainda aceitável
Trade-offs:
Random Forest: Melhor em precisão mas pior em recall
Regressão Logística: Melhor em recall mas pior em precisão
Recomendações:
Usar o Random Forest se o custo de falsos positivos for alto
Usar a Regressão Logística se for importante identificar o máximo possível de casos de churn
Considerar ensemble dos dois modelos para balancear os trade-offs
Esta análise fornece uma visão completa do desempenho dos modelos e suas características específicas, permitindo uma escolha informada dependendo dos objetivos do negócio.



Comparação dos Modelos:
Random Forest:
Accuracy: 0.8635 (86.35%)
Precision: 0.7939 (79.39%)
ROC AUC: 0.8520
F1-Score: 0.5701
Validação Cruzada (CV Score): 0.8523 ± 0.0066
Regressão Logística:
Accuracy: 0.7025 (70.25%)
Precision: 0.3792 (37.92%)
ROC AUC: 0.7807
F1-Score: 0.4979
Validação Cruzada (CV Score): 0.7709 ± 0.0118
O Random Forest se destacou por:
Maior acurácia geral (86.35% vs 70.25%)
Melhor precisão na identificação de churn (79.39% vs 37.92%)
Melhor capacidade de discriminação (ROC AUC = 0.8520 vs 0.7807)
Maior consistência na validação cruzada com menor variância
Por isso, na implementação da API, configuramos para usar o Random Forest. Agora precisamos salvar este modelo treinado usando joblib para que a API possa utilizá-lo. Você quer que eu ajude a salvar o modelo do notebook para usar na API?



O que é o FastAPI?
FastAPI é um framework moderno para construir APIs (Interface de Programação de Aplicações) com Python. É conhecido por ser:
Rápido em execução (um dos mais rápidos disponíveis)
Fácil de usar
Moderno (usa recursos recentes do Python)
Com documentação automática
Por que usar FastAPI no nosso projeto?
No nosso caso de previsão de churn, o FastAPI está sendo usado para:
Disponibilizar o Modelo:
Transformar nosso modelo de Machine Learning (Random Forest) em um serviço web
Permitir que outras aplicações façam previsões de churn usando nosso modelo
Tornar o modelo acessível via requisições HTTP
Estrutura da nossa API:
Vamos analisar o código que criamos:

@app.post("/predict", response_model=CustomerResponse)
async def predict_churn(customer: CustomerBase):
    try:
        # Converte o modelo Pydantic para dicionário
        customer_data = customer.dict()
        
        # Faz a predição
        churn_probability, is_likely_to_churn = predictor.predict(customer_data)
        
        # Retorna a resposta
        return CustomerResponse(
            churn_probability=float(churn_probability),
            is_likely_to_churn=bool(is_likely_to_churn)
        )


        omo funciona na prática:
Recebimento de Dados:
Um banco ou empresa envia os dados de um cliente via HTTP POST
Exemplo de dados enviados

{
    "credit_score": 619,
    "country": "France",
    "gender": "Female",
    "age": 42,
    "tenure": 2,
    "balance": 0.00,
    "products_number": 1,
    "credit_card": 1,
    "active_member": 1,
    "estimated_salary": 101348.88
}


Validação:
O FastAPI (usando Pydantic) automaticamente:
Verifica se todos os campos necessários estão presentes
Valida os tipos de dados (ex: age deve ser número inteiro)
Retorna erro claro se algo estiver errado
Processamento:
Os dados validados são enviados para nosso modelo
O modelo faz a previsão
A API retorna o resultado:


{
    "churn_probability": 0.75,
    "is_likely_to_churn": true
}



enefícios no nosso Projeto:
Documentação Automática:
Acesso a /docs mostra interface Swagger com todos os endpoints
Documentação interativa para testar a API
Exemplo: http://localhost:8000/docs
Validação de Dados:
Garantia que os dados recebidos estão no formato correto
Mensagens de erro claras quando algo está errado
Escalabilidade:
Múltiplos usuários podem fazer previsões simultaneamente
Fácil de implantar em serviços cloud (como Google Cloud)
Integração:
Outros sistemas podem facilmente se integrar com nosso modelo
Exemplo: Um sistema de CRM pode automaticamente checar o risco de churn de clientes
Exemplo Prático de Uso:
Quando a API estiver rodando:
Um sistema de atendimento ao cliente pode enviar dados de um cliente
Nossa API processa e retorna a probabilidade de churn
O sistema pode usar essa informação para:
Alertar sobre clientes em risco
Acionar equipe de retenção
Oferecer promoções específicas
Próximos Passos:
Salvar o modelo treinado
Rodar a API localmente para testes
Criar Dockerfile para containerização
Deploy no Google Cloud



Vou te explicar passo a passo como usar a interface do FastAPI para fazer uma predição:
Acesso à documentação interativa:
Abra seu navegador
Digite: http://localhost:8001/docs
Você verá a interface Swagger UI, que é uma página interativa para testar a API
Como fazer uma predição:
Na página, você verá um endpoint chamado POST /predict
Clique no botão verde que mostra "POST /predict"
Clique no botão "Try it out" (isso permite que você teste a API)
No campo "Request body", você verá um editor com um exemplo de JSON. Cole este exemplo:

   {
     "credit_score": 619,
     "country": "France",
     "gender": "Female",
     "age": 42,
     "tenure": 2,
     "balance": 0.00,
     "products_number": 1,
     "credit_card": 1,
     "active_member": 1,
     "estimated_salary": 101348.88
   }

   Clique no botão azul "Execute"
Role a página para baixo até a seção "Server response"
Você verá a resposta da API com:
A probabilidade de churn do cliente
Se o cliente tem probabilidade de cancelar (true/false)
A resposta será algo como:

{
  "churn_probability": 0.65,
  "is_likely_to_churn": true
}

churn_probability: 0.65
Este é um valor entre 0 e 1 (ou 0% a 100%)
0.65 significa 65% de probabilidade de churn
Quanto mais próximo de 1 (100%), maior a chance do cliente cancelar
Quanto mais próximo de 0 (0%), menor a chance do cliente cancelar
is_likely_to_churn: true
Este é um valor booleano (true/false) baseado em um threshold (limite) de 0.5 (50%)
Se a probabilidade for >= 0.5, retorna true (provável que vai cancelar)
Se a probabilidade for < 0.5, retorna false (provável que não vai cancelar)
No exemplo que você mostrou:
"churn_probability": 0.65 → 65% de chance de cancelar
"is_likely_to_churn": true → Como 0.65 é maior que 0.5, o modelo indica que este cliente provavelmente vai cancelar
Para comparação, veja outros exemplos:
Cliente com baixo risco de churn:


{
  "churn_probability": 0.15,
  "is_likely_to_churn": false
}

(15% de chance de cancelar - provavelmente não vai cancelar)
Cliente com alto risco de churn:


{
  "churn_probability": 0.89,
  "is_likely_to_churn": true
}

http://localhost:8001/docs

http://localhost:8001/redoc

image.png

Sim, funcionou perfeitamente! Agora estamos vendo diferentes predições para diferentes perfis de clientes. Vou explicar cada uma das predições que aparecem na imagem:
Cliente jovem com alto saldo:

"churn_probability": 0.01,
"is_likely_to_churn": false

Probabilidade de churn de apenas 1%
Este cliente tem baixíssima probabilidade de cancelar
Isso faz sentido porque:
Alto credit score (750)
Alto saldo (150.000)
É membro ativo
Tem cartão de crédito
Bom salário (80.000)



Cliente sênior com baixo engajamento

"churn_probability": 0.79,
"is_likely_to_churn": true

Probabilidade de churn de 79%
Este cliente tem alta probabilidade de cancelar
Isso faz sentido porque:
Baixo credit score (600)
Baixo saldo (5.000)
Não é membro ativo
Não tem cartão de crédito
Muitos produtos (3) - nosso modelo identificou que clientes com 3 produtos têm maior tendência a cancelar


"churn_probability": 0.09,
"is_likely_to_churn": false

Probabilidade de churn de 9%
Este cliente tem baixa probabilidade de cancelar
Isso faz sentido porque:
Credit score razoável (680)
Bom saldo (75.000)
É membro ativo
Tem cartão de crédito
Tempo de conta bom (8 anos)
Bom salário (95.000)
Estas predições mostram que o modelo está funcionando corretamente e fazendo distinções claras entre diferentes perfis de clientes. O modelo está identificando corretamente que:
Clientes ativos com bom engajamento têm menor probabilidade de churn
Clientes com baixo engajamento e muitos produtos têm maior probabilidade de churn
Fatores como saldo, credit score e ser membro ativo são importantes para a predição


## Comandos docker:

# Ver todos os containers (rodando ou não)
docker ps -a

# Parar o container
docker stop churn-prediction-api

# Iniciar o container
docker start churn-prediction-api

# Ver logs do container
docker logs churn-prediction-api


Função do Docker no nosso projeto de Data Science:
Portabilidade:
O Docker "empacota" toda nossa aplicação (código, modelo, dependências) em um container
Garante que a aplicação vai rodar igual em qualquer lugar (seu computador, servidor de produção, cloud)
Evita o famoso "na minha máquina funciona"
Isolamento:
Cada container é isolado do sistema operacional principal
As dependências do projeto não interferem com outros projetos
Versões específicas das bibliotecas (sklearn, pandas, etc.) ficam isoladas
Deployment mais fácil:
Facilita o deploy em serviços cloud (Google Cloud, AWS, Azure)
Não precisa se preocupar em instalar Python, bibliotecas, etc. no servidor
Tudo já está no container
Reprodutibilidade:
Qualquer pessoa pode rodar o modelo exatamente como foi treinado
Ambiente consistente entre desenvolvimento e produção
Versões das bibliotecas são fixas e documentadas
Escalabilidade:
Fácil de criar várias instâncias da API
Ideal para quando muitas pessoas precisam fazer predições ao mesmo tempo
Integração com ferramentas de orquestração (Kubernetes)

# Instalar o Portainer para gerenciar containers Docker
docker volume create portainer_data
docker run -d -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce


# Google cloud
Vou explicar detalhadamente como funciona o deployment no Google Cloud e como ele se integra com tudo que desenvolvemos até agora.
1. O que temos até agora:
Um modelo de Machine Learning treinado (Random Forest)
Uma API FastAPI que serve o modelo
Um dashboard Streamlit para interface com usuários
Tudo containerizado com Docker
2. O que é o Deployment no Google Cloud:
O deployment é o processo de disponibilizar nossa aplicação na nuvem, tornando-a acessível pela internet de forma segura e escalável. No Google Cloud, isso significa:
A. Infraestrutura como Serviço (IaaS)
Não precisamos nos preocupar com servidores físicos
Google cuida da manutenção do hardware
Podemos escalar recursos conforme necessário
B. Serviços que usaremos:
Google Container Registry (GCR)
Armazena nossas imagens Docker de forma segura
Como um "GitHub" para containers
Google Kubernetes Engine (GKE)
Orquestra nossos containers
Gerencia escalabilidade
Monitora saúde da aplicação
Cloud Storage
Armazena nosso modelo treinado
Mantém dados seguros
Cloud IAM
Gerencia permissões e acessos
Mantém a segurança da aplicação




